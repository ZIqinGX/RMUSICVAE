import click
import torch
import os
import shutil
import numpy as np
from torch.utils.data.dataset import TensorDataset
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
from matplotlib.image import NonUniformImage

from MeasureVAE.measure_vae import MeasureVAE
from MeasureVAE.vae_trainer import VAETrainer
from MeasureVAE.vae_tester import VAETester
from data.dataloaders.bar_dataset import *
from utils.helpers import *

# âœ… ç¡®ä¿ PyTorch å¤šè¿›ç¨‹æ­£ç¡®åˆå§‹åŒ–
if __name__ == '__main__':
    import torch.multiprocessing as mp
    mp.set_start_method('spawn', force=True)
    torch.serialization.add_safe_globals([TensorDataset])

print("PyTorchç‰ˆæœ¬:", torch.__version__)
print("CUDAæ˜¯å¦å¯ç”¨:", torch.cuda.is_available())
print("å½“å‰è®¾å¤‡:", torch.cuda.current_device())
print("è®¾å¤‡åç§°:", torch.cuda.get_device_name(0))

@click.command()
@click.option('--batch_size', default=64, help='Training batch size')
@click.option('--num_epochs', default=50, help='Number of training epochs')
@click.option('--train/--test', default=False, help='Train or test the model')
def main(batch_size, num_epochs, train):

    # âœ… 1ï¸âƒ£ ç¡®ä¿ `datasets/` ç›®å½•æ¸…ç†
    dataset_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'datasets')
    if os.path.exists(dataset_dir):
        print("âš ï¸  å‘ç°æ—§æ•°æ®é›†ï¼Œåˆ é™¤ `datasets/` ç›®å½•...")
        shutil.rmtree(dataset_dir)
    os.makedirs(dataset_dir, exist_ok=True)

    # âœ… 2ï¸âƒ£ é‡æ–°åŠ è½½æ•°æ®é›†
    print("ğŸ“¥ é‡æ–°åŠ è½½ `FolkNBarDataset` æ•°æ®é›†...")
    is_short = True  # âœ… **ç¡®ä¿æ•°æ®é›†å°ä¸€äº›**
    #is_short = False
    num_bars = 1

    folk_dataset_train = FolkNBarDataset(
        dataset_type='train',
        is_short=is_short,
        num_bars=num_bars
    )
    folk_dataset_test = FolkNBarDataset(
        dataset_type='test',
        is_short=is_short,
        num_bars=num_bars
    )

    # âœ… 3ï¸âƒ£ åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataloader, val_dataloader, test_dataloader = folk_dataset_train.data_loaders(
        batch_size=batch_size, split=(0.7, 0.2)
    )

    # âœ… **æ‰“å°æ•°æ®é›†å¤§å°ï¼Œç¡®è®¤æ˜¯å¦æ­£ç¡®**
    print(f"âœ… è®­ç»ƒæ•°æ®é›†æ€»å¤§å°: {len(train_dataloader.dataset)} ")
    print(f"âœ… è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_dataloader)} (batch_size={batch_size})")

    # âœ… 4ï¸âƒ£ åˆå§‹åŒ– VAE æ¨¡å‹
    model = MeasureVAE(
        dataset=folk_dataset_train,
        note_embedding_dim=10,
        metadata_embedding_dim=2,
        num_encoder_layers=2,
        encoder_hidden_size=512,
        encoder_dropout_prob=0.5,
        latent_space_dim=256,
        num_decoder_layers=2,
        decoder_hidden_size=512,
        decoder_dropout_prob=0.5,
        has_metadata=False
    )

    # âœ… 5ï¸âƒ£ å°†æ¨¡å‹ç§»åŠ¨åˆ° GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")

    # âœ… 6ï¸âƒ£ è®­ç»ƒæˆ–æµ‹è¯•æ¨¡å‹
    if train:
        print("ğŸš€ è®­ç»ƒæ¨¡å¼å¯åŠ¨...")

        trainer = VAETrainer(
            dataset=folk_dataset_train,
            model=model,
            lr=1e-4,
            has_reg_loss=True,
            reg_type='rhy_complexity',
            reg_dim=0
        )

        # âœ… è¿™é‡Œä¿®å¤ `train_model()` çš„å‚æ•°ï¼Œåˆ é™¤ `data_loader`
        trainer.train_model(
            batch_size=batch_size,
            num_epochs=num_epochs,
            plot=True,
            log=True,
        )

# **************************************************  è¯„ä¼°  **************************************************************************************
    else:
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼å¯åŠ¨...")
        model.load()
        model.to(device)
        model.eval()

        tester = VAETester(
            dataset=folk_dataset_test,
            model=model,
            has_reg_loss=True,
            reg_type='rhy_complexity',
            reg_dim=0
        )

        print("ğŸ¯ è¯„ä¼°æ¨¡å‹...")
        tester.test_model(batch_size=batch_size)

if __name__ == '__main__':
    main()
